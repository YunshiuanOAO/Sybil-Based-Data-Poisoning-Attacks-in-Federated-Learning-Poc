#!/usr/bin/env python3
"""
æ”»æ“Šæ–¹æ³•æ¯”è¼ƒè…³æœ¬
================

æ¯”è¼ƒæˆ‘å€‘çš„è™›æ“¬æ•¸æ“šæ”»æ“Šèˆ‡ SPoiL é¢¨æ ¼çš„æ¨™ç±¤ç¿»è½‰æ”»æ“Š
ä½¿ç”¨ Main Task Accuracy å’Œ Poisoning Success Rate è©•ä¼°

Author: Security Research Team
Date: 2024
"""

import json
import sys
from datetime import datetime
from pathlib import Path

def main():
    """ä¸»å‡½æ•¸ - é‹è¡Œæ”»æ“Šæ¯”è¼ƒå¯¦é©—"""
    
    print("ğŸ”¬ æ”»æ“Šæ–¹æ³•æ¯”è¼ƒå¯¦é©—")
    print("=" * 70)
    print("ğŸ“Š æ¯”è¼ƒç›®æ¨™:")
    print("   1. è™›æ“¬æ•¸æ“šæ”»æ“Š (æˆ‘å€‘çš„å¯¦ç¾)")
    print("   2. SPoiL æ¨™ç±¤ç¿»è½‰æ”»æ“Š (2023è«–æ–‡)")
    print("ğŸ“ˆ è©•ä¼°æŒ‡æ¨™:")
    print("   - Main Task Accuracy (MTA)")
    print("   - Poisoning Success Rate (PSR)")
    print("   - Attack Persistence")
    print("   - Relative Performance Degradation")
    print("=" * 70)
    
    try:
        from setup import quick_setup
        from environment import FederatedLearningEnvironment
        from attack import create_attack_orchestrator, ATTACK_SCENARIOS
        
        # ç’°å¢ƒè¨­ç½®
        print("ğŸ”§ åˆå§‹åŒ–ç’°å¢ƒ...")
        setup_success, config = quick_setup()
        if not setup_success:
            print("âŒ ç’°å¢ƒè¨­ç½®å¤±æ•—")
            sys.exit(1)
        
        # å‰µå»ºè¯é‚¦å­¸ç¿’ç’°å¢ƒ
        fl_env = FederatedLearningEnvironment(
            num_honest_clients=5,
            num_sybil_clients=3,
            poison_ratio=0.3
        )
        
        # æ”»æ“Šå ´æ™¯é…ç½®
        attack_scenarios = [
            ('paper_replica', 'è™›æ“¬æ•¸æ“šæ”»æ“Š (è«–æ–‡å¯¦ç¾)'),
            ('spoil_replica', 'SPoiL æ¨™ç±¤ç¿»è½‰æ”»æ“Š (2023)')
        ]
        
        results_comparison = []
        
        for scenario_name, description in attack_scenarios:
            print(f"\nğŸ¯ åŸ·è¡Œæ”»æ“Š: {description}")
            print("-" * 50)
            
            # é‡æ–°å‰µå»ºç’°å¢ƒä»¥ç¢ºä¿å…¬å¹³æ¯”è¼ƒ
            fl_env = FederatedLearningEnvironment(
                num_honest_clients=5,
                num_sybil_clients=3,
                poison_ratio=0.3
            )
            
            # å‰µå»ºæ”»æ“Šç·¨æ’å™¨
            scenario_config = ATTACK_SCENARIOS[scenario_name]
            attack_orchestrator = create_attack_orchestrator(
                fl_env, 
                num_sybil_per_malicious=scenario_config.get('num_sybil_per_malicious', 5)
            )
            
            # åŸ·è¡Œæ”»æ“Š
            results = attack_orchestrator.run_attack_simulation(
                total_rounds=scenario_config['total_rounds'],
                attack_start_round=scenario_config['attack_start_round'],
                attack_method=scenario_config.get('attack_method', 'virtual_data'),
                verbose=True
            )
            
            # ä¿å­˜çµæœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"attack_comparison_{scenario_name}_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {filename}")
            
            # æ”¶é›†æ¯”è¼ƒæ•¸æ“š
            attack_results = results['results']
            results_comparison.append({
                'scenario': scenario_name,
                'description': description,
                'attack_method': scenario_config.get('attack_method', 'virtual_data'),
                'metrics': {
                    'main_task_accuracy': attack_results.get('main_task_accuracy', 0),
                    'poisoning_success_rate': attack_results.get('poisoning_success_rate', 0),
                    'attack_persistence': attack_results.get('attack_persistence', 0),
                    'relative_performance_degradation': attack_results.get('relative_performance_degradation', 0),
                    'max_accuracy_drop': attack_results.get('max_accuracy_drop', 0),
                    'effectiveness_level': attack_results.get('effectiveness_level', 'unknown')
                },
                'config': {
                    'total_rounds': scenario_config['total_rounds'],
                    'attack_start_round': scenario_config['attack_start_round'],
                    'num_sybil_per_malicious': scenario_config.get('num_sybil_per_malicious', 5)
                }
            })
        
        # ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
        print("\n" + "=" * 70)
        print("ğŸ“Š æ”»æ“Šæ•ˆæœæ¯”è¼ƒå ±å‘Š")
        print("=" * 70)
        
        print("\nğŸ“ˆ æ ¸å¿ƒæŒ‡æ¨™å°æ¯”:")
        print("-" * 70)
        print(f"{'æŒ‡æ¨™':<25} {'è™›æ“¬æ•¸æ“šæ”»æ“Š':<15} {'SPoiLæ”»æ“Š':<15} {'å„ªå‹¢'}")
        print("-" * 70)
        
        if len(results_comparison) >= 2:
            virtual_data = results_comparison[0]['metrics']
            spoil_attack = results_comparison[1]['metrics']
            
            # Main Task Accuracy (è¶Šä½è¶Šå¥½ï¼Œè¡¨ç¤ºæ”»æ“Šè¶Šæœ‰æ•ˆ)
            print(f"{'Main Task Accuracy':<25} {virtual_data['main_task_accuracy']:<15.4f} {spoil_attack['main_task_accuracy']:<15.4f} {'SPoiL' if spoil_attack['main_task_accuracy'] < virtual_data['main_task_accuracy'] else 'è™›æ“¬æ•¸æ“š'}")
            
            # Poisoning Success Rate (è¶Šé«˜è¶Šå¥½)
            print(f"{'Poisoning Success Rate':<25} {virtual_data['poisoning_success_rate']:<15.2%} {spoil_attack['poisoning_success_rate']:<15.2%} {'SPoiL' if spoil_attack['poisoning_success_rate'] > virtual_data['poisoning_success_rate'] else 'è™›æ“¬æ•¸æ“š'}")
            
            # Attack Persistence (è¶Šé«˜è¶Šå¥½)
            print(f"{'Attack Persistence':<25} {virtual_data['attack_persistence']:<15.2%} {spoil_attack['attack_persistence']:<15.2%} {'SPoiL' if spoil_attack['attack_persistence'] > virtual_data['attack_persistence'] else 'è™›æ“¬æ•¸æ“š'}")
            
            # Relative Performance Degradation (è¶Šé«˜è¶Šå¥½)
            print(f"{'Performance Degradation':<25} {virtual_data['relative_performance_degradation']:<15.2%} {spoil_attack['relative_performance_degradation']:<15.2%} {'SPoiL' if spoil_attack['relative_performance_degradation'] > virtual_data['relative_performance_degradation'] else 'è™›æ“¬æ•¸æ“š'}")
            
            # Max Accuracy Drop (è¶Šé«˜è¶Šå¥½)
            print(f"{'Max Accuracy Drop':<25} {virtual_data['max_accuracy_drop']:<15.4f} {spoil_attack['max_accuracy_drop']:<15.4f} {'SPoiL' if spoil_attack['max_accuracy_drop'] > virtual_data['max_accuracy_drop'] else 'è™›æ“¬æ•¸æ“š'}")
        
        print("\nğŸ¯ æ•ˆæœç­‰ç´šå°æ¯”:")
        for result in results_comparison:
            print(f"   {result['description']}: {result['metrics']['effectiveness_level']}")
        
        print("\nğŸ“‹ æ”»æ“Šé…ç½®å°æ¯”:")
        for result in results_comparison:
            config = result['config']
            print(f"\n{result['description']}:")
            print(f"   - ç¸½è¼ªæ•¸: {config['total_rounds']}")
            print(f"   - æ”»æ“Šé–‹å§‹è¼ª: {config['attack_start_round']}")
            print(f"   - Sybilç¯€é»æ•¸: {config['num_sybil_per_malicious']}")
            print(f"   - æ”»æ“Šæ–¹æ³•: {result['attack_method']}")
        
        # ä¿å­˜æ¯”è¼ƒçµæœ
        comparison_report = {
            'timestamp': datetime.now().isoformat(),
            'comparison_results': results_comparison,
            'summary': {
                'virtual_data_effectiveness': results_comparison[0]['metrics']['effectiveness_level'] if len(results_comparison) > 0 else 'unknown',
                'spoil_effectiveness': results_comparison[1]['metrics']['effectiveness_level'] if len(results_comparison) > 1 else 'unknown',
            }
        }
        
        comparison_filename = f"attack_comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(comparison_filename, 'w', encoding='utf-8') as f:
            json.dump(comparison_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å®Œæ•´æ¯”è¼ƒå ±å‘Šå·²ä¿å­˜: {comparison_filename}")
        
        print("\nğŸ” çµè«–:")
        if len(results_comparison) >= 2:
            virtual_psr = results_comparison[0]['metrics']['poisoning_success_rate']
            spoil_psr = results_comparison[1]['metrics']['poisoning_success_rate']
            
            if virtual_psr > spoil_psr:
                print("   è™›æ“¬æ•¸æ“šæ”»æ“Šåœ¨æŠ•æ¯’æˆåŠŸç‡æ–¹é¢è¡¨ç¾æ›´å„ª")
            elif spoil_psr > virtual_psr:
                print("   SPoiL æ¨™ç±¤ç¿»è½‰æ”»æ“Šåœ¨æŠ•æ¯’æˆåŠŸç‡æ–¹é¢è¡¨ç¾æ›´å„ª")
            else:
                print("   å…©ç¨®æ”»æ“Šæ–¹æ³•åœ¨æŠ•æ¯’æˆåŠŸç‡æ–¹é¢è¡¨ç¾ç›¸ç•¶")
        
        print("\nğŸ‰ æ”»æ“Šæ¯”è¼ƒå¯¦é©—å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ å¯¦é©—éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 